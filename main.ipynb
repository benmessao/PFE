{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('./source/src/')\n",
    "import dataset_prep\n",
    "from dataset_prep import *\n",
    "from new_features import *\n",
    "\n",
    "\n",
    "sys.path.append('./source/deep learning/')\n",
    "from models import *\n",
    "from litterature import *\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers, applications, utils, models, optimizers, Input, callbacks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin du dossier contenant tous les .csv\n",
    "data_folder = './data'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création des csv avec les nouvelles features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nécessite les csv suivants : \n",
    " - `merged1.csv`  (DoS - 13)\n",
    " - `merged2.csv`   (DoS Random - 14)\n",
    " - `merged3.csv`   (DoS Disruptive - 15)\n",
    " - `merged4.csv`   (Dos Random Sybil - 18)\n",
    " - `merged5.csv`   (Dos Disruptive Sybil - 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DoS - 13\n",
    "df_dos_random = pd.read_csv(data_folder+'/1416/merged1.csv')\n",
    "# Create a new csv file with new features from merged2.csv\n",
    "new_features(df_dos_random).to_csv(os.path.join(data_folder + '', 'DoS_0709_new_columns.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.value_counts of 0          13\n",
       "1          13\n",
       "2          13\n",
       "3          13\n",
       "4          13\n",
       "           ..\n",
       "1242774     0\n",
       "1242775     0\n",
       "1242776     0\n",
       "1242777     0\n",
       "1242778    13\n",
       "Name: labelRec, Length: 1242779, dtype: int64>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vérifiaction des labels\n",
    "df_dos_random.labelRec.value_counts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe selection \n",
    "\n",
    "Importation de la base de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colonnes choisies - label, sender & sendTime obligatoires\n",
    "# Colonnes supprimées pour le test : \"distRealSR2\", \"senderPseudo\", \"sender\", \"sendTime\", \"scenario\", \"rcvTime\"\n",
    "\n",
    "# selected_columns = [\n",
    "# \"nb_packets_sent\",\n",
    "# \"distance\",\n",
    "# \"distRealSR1\",\n",
    "# \"pos_y_rec_f\",\n",
    "# \"pos_y_rec\",\n",
    "# \"pos_x_rec_f\",\n",
    "# \"pos_x_rec\",\n",
    "# \"pos_x_send\",\n",
    "# \"pos_y_send\",\n",
    "# \"spd_x_send\",\n",
    "# \"spd_y_send\",\n",
    "# \"sendTime\",\n",
    "# \"receiver\",\n",
    "# \"sender\",\n",
    "# \"messageID\",\n",
    "# \"label\"\n",
    "# ]\n",
    "selected_columns = [\n",
    "\"distance\",\n",
    "\"pos_x_send\",\n",
    "\"pos_y_send\",\n",
    "\"pos_x_send_f\",\n",
    "\"pos_y_send_f\",\n",
    "\"spd_x_send\",\n",
    "\"spd_y_send\",\n",
    "\"sendTime\",\n",
    "\"sender\",\n",
    "\"label\"\n",
    "]\n",
    "\n",
    "input_sequence_shape = len(selected_columns)-2 # On drop label et sender dans la création de séquences\n",
    "\n",
    "data_type = {\n",
    "    \"label\":\"int8\",\n",
    "    \"sender\":\"int16\",\n",
    "    \"receiver\":\"int16\",\n",
    "    \"nb_packets_sent\":\"int16\"\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes avant nettoyage :  1242779\n",
      "Nombre de lignes après nettoyage :  1233657\n"
     ]
    }
   ],
   "source": [
    "# DoS (13)\n",
    "df_13 = dataset_prep.import_dataset(\"./data/1416/merged1.csv\", selected_columns, data_type)\n",
    "df_13.name = 'DoS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DoS Random (14)\n",
    "df_14 = dataset_prep.import_dataset(data_folder + '/DoS_Random_0709_new_columns.csv', selected_columns, data_type)\n",
    "df_14.name = 'DoS Random'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DoS Disruptive (15)\n",
    "df_15 = dataset_prep.import_dataset(data_folder + '/DoS_Disruptive_0709_new_columns.csv', selected_columns)\n",
    "df_15.name = 'DoS Disruptive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DoS Random Sybil (18)\n",
    "df_18 = dataset_prep.import_dataset(data_folder + '/DoS_Random_Sybil_0709_new_columns.csv', selected_columns)\n",
    "df_18.name = 'DoS Random Sybil'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DoS Disruptive Sybil (19)\n",
    "df_19 = dataset_prep.import_dataset(data_folder + '/DoS_Disruptive_Sybil_0709_new_columns.csv', selected_columns)\n",
    "df_19.name = 'DoS Disruptive Sybil'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(verbose=True, memory_usage='deep', show_counts=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de séquences :  120781\n",
      "X_train :  (108702, 20, 8)\n",
      "y_train :  (108702,)\n",
      "X_test :  (12079, 20, 8)\n",
      "y_test :  (12079,)\n"
     ]
    }
   ],
   "source": [
    "# Séparation en données d'entrainement et de test\n",
    "X_train, X_test, y_train, y_test = dataset_prep.data_preparation(df_13, sample=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etude individuelle d'un model\n",
    "\n",
    "- dense_network(input_sequence_shape) : 3-sende layers\n",
    "- stacked_RNN_small(hidden_units, dense_units, input_shape, activation) : 2 stacked RNN\n",
    "- stacked_LSTM_small(input_sequence_shape) : 2 stacked LSTM\n",
    "- mix_rnn_lstm(input_sequence_shape) : simple LSTM + 2-stacked RNN\n",
    "- simple_GRU(input_sequence_shape) : simple GRU (256)\n",
    "- stacked_GRU(input_sequence_shape) : 3-stacked GRU\n",
    "- stacked_LSTM(input_sequence_shape) : 3-stacked LSTM\n",
    "- stacked_RNN(input_sequence_shape) : 3-stacked RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix et compilation du modèle\n",
    "simple_model = dense_network(input_sequence_shape)\n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "#opt = keras.optimizers.SGD(learning_rate=0.01)\n",
    "simple_model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = simple_model.fit(X_train, y_train, epochs=20, batch_size=128, validation_split=0.3, callbacks=[callback])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichage des schémas & matrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:, ['accuracy', 'val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df.loc[:, ['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2873 - accuracy: 0.5606\n",
      "Evaluation du modèle : [0.2872598171234131, 0.560606062412262]\n",
      "7/7 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(33.0, 0.5, 'True Labels')"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Evaluation du modèle : {simple_model.evaluate(X_test, y_test)}\")\n",
    "y_pred = simple_model.predict(X_test)\n",
    "preds = np.round(y_pred).astype(int)\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "fig, ax = plt.subplots(figsize=(6,6)) \n",
    "sns.heatmap(cm, annot=True, cbar=False, cmap='Blues')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tous les modèles\n",
    "\n",
    "### Entrainement des modèles pour chaque dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attack_types = [13, 14, 15, 18, 19]\n",
    "attack_types = [13, 14]\n",
    "# dataframes = [df_13, df_14, df_15, df_18, df_19]\n",
    "dataframes = [df_13, df_14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "VAL_SPLIT = 0.3\n",
    "ADAM = keras.optimizers.Adam(learning_rate=0.0003)\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_dataframe = pd.DataFrame()\n",
    "for i in range(len(dataframes)):\n",
    "    X_train, X_test, y_train, y_test = dataset_prep.data_preparation(dataframes[i], sample=False)\n",
    "\n",
    "    # 2-stacked RNN\n",
    "    print(\"\\nTraining 2 stacked RNN model\\n\")\n",
    "    rnn_model = stacked_RNN_small(input_sequence_shape=input_sequence_shape)\n",
    "    rnn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics='accuracy')\n",
    "    history = rnn_model.fit(X_train, y_train, epochs=EPOCHS, batch_size=128, validation_split=VAL_SPLIT, callbacks=[callback])\n",
    "    eval=rnn_model.evaluate(X_test, y_test)\n",
    "    evaluation_dataframe = pd.concat([evaluation_dataframe, pd.DataFrame({'dataset':[attack_types[i]], 'modele':['2-stacked-rnn'], 'accuracy':[eval[1]]})])\n",
    "\n",
    "    # stacked LSTM small\n",
    "    print(\"\\nTraining stacked small LSTM model\\n\")\n",
    "    lstm_model = stacked_LSTM_small(input_sequence_shape)\n",
    "    opt = keras.optimizers.SGD(learning_rate=0.01)\n",
    "    lstm_model.compile(loss='binary_crossentropy', optimizer=opt, metrics='accuracy')\n",
    "    history = lstm_model.fit(X_train, y_train, epochs=EPOCHS, batch_size=32, validation_split=VAL_SPLIT, callbacks=[callback])\n",
    "    eval=lstm_model.evaluate(X_test, y_test)\n",
    "    evaluation_dataframe = pd.concat([evaluation_dataframe, pd.DataFrame({'dataset':[attack_types[i]], 'modele':['stacked-small-lstm'], 'accuracy':[eval[1]]})])\n",
    "\n",
    "    # mix lstm rnn\n",
    "    print(\"\\nTraining RNN-LSTM model\\n\")\n",
    "    lstm_rnn_model = mix_rnn_lstm(input_sequence_shape)\n",
    "    opt = keras.optimizers.SGD(learning_rate=0.01)\n",
    "    lstm_rnn_model.compile(loss='binary_crossentropy', optimizer=opt, metrics='accuracy')\n",
    "    history = lstm_rnn_model.fit(X_train, y_train, epochs=EPOCHS, batch_size=32, validation_split=VAL_SPLIT, callbacks=[callback])\n",
    "    eval=lstm_rnn_model.evaluate(X_test, y_test)\n",
    "    evaluation_dataframe = pd.concat([evaluation_dataframe, pd.DataFrame({'dataset':[attack_types[i]], 'modele':['lstm-rnn'], 'accuracy':[eval[1]]})])\n",
    "\n",
    "    # 3 Stacked GRU\n",
    "    print(\"\\nTraining 3 stacked GRU\\n\")\n",
    "    stacked_GRU_model = stacked_GRU(input_sequence_shape)\n",
    "    opt = keras.optimizers.SGD(learning_rate=0.01)\n",
    "    stacked_GRU_model.compile(loss='binary_crossentropy', optimizer=opt, metrics='accuracy')\n",
    "    history = stacked_GRU_model.fit(X_train, y_train, epochs=EPOCHS, batch_size=64, validation_split=VAL_SPLIT, callbacks=[callback])\n",
    "    eval=stacked_GRU_model.evaluate(X_test, y_test)\n",
    "    evaluation_dataframe = pd.concat([evaluation_dataframe, pd.DataFrame({'dataset':[attack_types[i]], 'modele':['3-stacked-GRU'], 'accuracy':[eval[1]]})])\n",
    "\n",
    "    # simple GRU\n",
    "    print(\"\\nTraining simple GRU\\n\")\n",
    "    simple_GRU_model = simple_GRU(input_sequence_shape)\n",
    "    opt = keras.optimizers.SGD(learning_rate=0.01)\n",
    "    simple_GRU_model.compile(loss='binary_crossentropy', optimizer=opt, metrics='accuracy')\n",
    "    history = simple_GRU_model.fit(X_train, y_train, epochs=EPOCHS, batch_size=64, validation_split=VAL_SPLIT, callbacks=[callback])\n",
    "    eval=simple_GRU_model.evaluate(X_test, y_test)\n",
    "    evaluation_dataframe = pd.concat([evaluation_dataframe, pd.DataFrame({'dataset':[attack_types[i]], 'modele':['simple-gru'], 'accuracy':[eval[1]]})])\n",
    "\n",
    "    # stacked LSTM\n",
    "    print(\"\\nTraining 3 stacked LSTM\\n\")\n",
    "    stacked_LSTM_model = stacked_LSTM(input_sequence_shape)\n",
    "    stacked_LSTM_model.compile(loss='mean_absolute_error', optimizer=ADAM, metrics='accuracy')\n",
    "    history = stacked_LSTM_model.fit(X_train, y_train, epochs=EPOCHS, batch_size=64, validation_split=VAL_SPLIT, callbacks=[callback])\n",
    "    eval = stacked_LSTM_model.evaluate(X_test, y_test)\n",
    "    evaluation_dataframe = pd.concat([evaluation_dataframe, pd.DataFrame({'dataset':[attack_types[i]], 'modele':['3-stacked-LSTM'], 'accuracy':[eval[1]]})])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle de littérature\n",
    "\n",
    "### Préparation des données \n",
    "\n",
    "Modèle CNN LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation en données d'entrainement et de test\n",
    "X_train, X_test, y_train, y_test = dataset_prep.data_preparation_cnnlstm(df, sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input shape cnn lstm : X_train.shape[1:]\n",
    "litterature_model = CNN_LSTM_1(X_train.shape[1:])\n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "history = litterature_model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.3, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Evaluation du modèle : {litterature_model.evaluate(X_test, y_test)}\")\n",
    "\n",
    "y_pred = litterature_model.predict(X_test)\n",
    "preds = np.round(y_pred).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_test, preds, normalize='all')\n",
    "fig, ax = plt.subplots(figsize=(6,6)) \n",
    "\n",
    "sns.heatmap(cm, annot=True, cbar=False, cmap='Blues')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:, ['accuracy', 'val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df.loc[:, ['loss', 'val_loss']].plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement des modèles de littérature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "VAL_SPLIT = 0.3\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4, restore_best_weights=True)\n",
    "\n",
    "evaluation_litterature = pd.DataFrame()\n",
    "for i in range(len(dataframes)):\n",
    "    X_train, X_test, y_train, y_test = dataset_prep.data_preparation(dataframes[i], sample=False)\n",
    "\n",
    "    # CNN LSTM n°2\n",
    "    # 43%\n",
    "    print(\"\\nTraining CNN_LSTM_2 model\\n\")\n",
    "    CNN_LSTM_2_model = CNN_LSTM_2(input_sequence_shape=X_train.shape[1:])\n",
    "    history = CNN_LSTM_2_model.fit(X_train, y_train, epochs=EPOCHS, batch_size=128, validation_split=VAL_SPLIT, callbacks=[callback])\n",
    "    eval=CNN_LSTM_2_model.evaluate(X_test, y_test)\n",
    "    evaluation_litterature = pd.concat([evaluation_litterature, pd.DataFrame({'dataset':[attack_types[i]], 'modele':['2-stacked-rnn'], 'accuracy':[eval[1]]})])\n",
    "    \n",
    "    # 3 stacked LSTM\n",
    "    #83,50%\n",
    "    print(\"\\nTraining 3_LSTM model\\n\")\n",
    "    three_LSTM_model = three_LSTM(input_sequence_shape=X_train.shape[1:])\n",
    "    history = three_LSTM_model.fit(X_train, y_train, epochs=EPOCHS, batch_size=128, validation_split=VAL_SPLIT, callbacks=[callback])\n",
    "    eval=three_LSTM_model.evaluate(X_test, y_test)\n",
    "    evaluation_litterature = pd.concat([evaluation_litterature, pd.DataFrame({'dataset':[attack_types[i]], 'modele':['2-stacked-rnn'], 'accuracy':[eval[1]]})])\n",
    "    \n",
    "    # 4 stacked LSTM\n",
    "    #83,79%\n",
    "    print(\"\\nTraining 4_LSTM model\\n\")\n",
    "    four_LSTM_model = four_LSTM(input_sequence_shape=X_train.shape[1:])\n",
    "    history = four_LSTM_model.fit(X_train, y_train, epochs=EPOCHS, batch_size=128, validation_split=VAL_SPLIT, callbacks=[callback])\n",
    "    eval=four_LSTM_model.evaluate(X_test, y_test)\n",
    "    evaluation_litterature = pd.concat([evaluation_litterature, pd.DataFrame({'dataset':[attack_types[i]], 'modele':['2-stacked-rnn'], 'accuracy':[eval[1]]})])\n",
    "    \n",
    "    # 5 stacked LSTM\n",
    "    #83,57%\n",
    "    print(\"\\nTraining 5_LSTM model\\n\")\n",
    "    five_LSTM_model = five_LSTM(input_sequence_shape=X_train.shape[1:])\n",
    "    history = five_LSTM_model.fit(X_train, y_train, epochs=EPOCHS, batch_size=128, validation_split=VAL_SPLIT, callbacks=[callback])\n",
    "    eval=five_LSTM_model.evaluate(X_test, y_test)\n",
    "    evaluation_litterature = pd.concat([evaluation_litterature, pd.DataFrame({'dataset':[attack_types[i]], 'modele':['2-stacked-rnn'], 'accuracy':[eval[1]]})])\n",
    "    \n",
    "    # 4 stacked LSTM n°2\n",
    "    #83,59%\n",
    "    print(\"\\nTraining LSTM model\\n\")\n",
    "    LSTM_model = LSTM_1(input_sequence_shape=X_train.shape[1:])\n",
    "    history = LSTM_model.fit(X_train, y_train, epochs=EPOCHS, batch_size=128, validation_split=VAL_SPLIT, callbacks=[callback])\n",
    "    eval=LSTM_model.evaluate(X_test, y_test)\n",
    "    evaluation_litterature = pd.concat([evaluation_litterature, pd.DataFrame({'dataset':[attack_types[i]], 'modele':['2-stacked-rnn'], 'accuracy':[eval[1]]})])\n",
    "    \n",
    "    # CNN LSTM n°3\n",
    "    #44,06%\n",
    "    print(\"\\nTraining CNN_LSTM_3 model\\n\")\n",
    "    CNN_LSTM_3_model = CNN_LSTM_3(input_sequence_shape=X_train.shape[1:])\n",
    "    history = CNN_LSTM_3_model.fit(X_train, y_train, epochs=EPOCHS, batch_size=128, validation_split=VAL_SPLIT, callbacks=[callback])\n",
    "    eval=CNN_LSTM_3_model.evaluate(X_test, y_test)\n",
    "    evaluation_litterature = pd.concat([evaluation_litterature, pd.DataFrame({'dataset':[attack_types[i]], 'modele':['2-stacked-rnn'], 'accuracy':[eval[1]]})])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_litterature.to_csv('results_litterature.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62676a739a12458da1789023e3b8ff577b389322e46d1a1cbf9699674fd76d84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
