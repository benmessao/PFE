{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [],
         "source": [
            "import pandas as pd\n",
            "import numpy as np\n",
            "from tensorflow import keras\n",
            "from keras import layers, applications, utils, models, optimizers, Input, callbacks\n",
            "from keras.models import Sequential\n",
            "from keras.layers import Dense, SimpleRNN\n",
            "from sklearn.model_selection import train_test_split"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Code pour modèles et préparation des données"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Modèles"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [],
         "source": [
            "def dense_network(input_sequence_shape):\n",
            "    simple_model = keras.Sequential(\n",
            "        [\n",
            "            layers.Dense(\n",
            "                128, input_shape=(20, input_sequence_shape), activation=\"relu\"\n",
            "            ),\n",
            "            # layers.BatchNormalization(), # les batchNormalization fond baisser l'accuracy\n",
            "            layers.Dense(256, activation=\"relu\"),\n",
            "            # layers.BatchNormalization(),\n",
            "            layers.Dense(64, activation=\"relu\"),\n",
            "            layers.Dense(1, activation=\"linear\"),  # avec relu on perd un peu d'accuracy\n",
            "        ]\n",
            "    )\n",
            "    return simple_model\n",
            "\n",
            "\n",
            "def stacked_RNN(\n",
            "    hidden_units=32, dense_units=1, input_shape=(20, 13), activation=[\"relu\", \"relu\"]\n",
            "):\n",
            "    \"\"\"\n",
            "    hidden_units : nombre de neurones dans la couche SimpleRNN\n",
            "    dense_units : nombre de neurones dans la couche Dense\n",
            "    activation : liste des deux fonctions d'activation\n",
            "    \"\"\"\n",
            "\n",
            "    model = Sequential()\n",
            "    model.add(\n",
            "        SimpleRNN(\n",
            "            hidden_units,\n",
            "            input_shape=input_shape,\n",
            "            return_sequences=True,\n",
            "            activation=activation[0],\n",
            "        )\n",
            "    )\n",
            "    model.add(SimpleRNN(32, activation=activation[0]))\n",
            "    model.add(keras.layers.BatchNormalization())\n",
            "    model.add(Dense(64, activation=activation[1]))\n",
            "    model.add(Dense(units=dense_units, activation=\"sigmoid\"))\n",
            "\n",
            "    return model\n",
            "\n",
            "\n",
            "def stacked_LSTM_small(input_sequence_shape):\n",
            "    lstm_model = keras.Sequential(\n",
            "        [\n",
            "            layers.Dense(32, input_shape=(20, input_sequence_shape), activation=\"relu\"),\n",
            "            layers.LSTM(128, return_sequences=True),\n",
            "            layers.LSTM(128),\n",
            "            # layers.BatchNormalization(),\n",
            "            layers.Dense(64, activation=\"relu\"),\n",
            "            layers.Dense(1, activation=\"sigmoid\"),\n",
            "        ]\n",
            "    )\n",
            "    return lstm_model\n",
            "\n",
            "\n",
            "# Mix\n",
            "def mix_rnn_lstm(input_sequence_shape):\n",
            "    lstm_rnn_model = keras.Sequential(\n",
            "        [\n",
            "            layers.Dense(32, input_shape=(20, input_sequence_shape), activation=\"relu\"),\n",
            "            layers.LSTM(\n",
            "                128, return_sequences=True, activation=\"relu\"\n",
            "            ),  # return_sequences à True pour que la sortie soit de dimension 3\n",
            "            layers.BatchNormalization(),\n",
            "            layers.Dense(64, activation=\"relu\"),\n",
            "            layers.SimpleRNN(64, activation=\"relu\", return_sequences=True),\n",
            "            layers.SimpleRNN(32, activation=\"relu\"),\n",
            "            layers.BatchNormalization(),\n",
            "            layers.Dense(64, activation=\"relu\"),\n",
            "            # layers.Dropout(0.5),\n",
            "            layers.Dense(1, activation=\"sigmoid\"),\n",
            "        ]\n",
            "    )\n",
            "    return lstm_rnn_model\n",
            "\n",
            "\n",
            "# Single GRU layer of 256 units\n",
            "def simple_GRU(input_sequence_shape):\n",
            "    simple_GRU = keras.models.Sequential()\n",
            "    simple_GRU.add(\n",
            "        keras.layers.Dense(\n",
            "            32, input_shape=(20, input_sequence_shape), activation=\"relu\"\n",
            "        )\n",
            "    )\n",
            "    simple_GRU.add(keras.layers.Dropout(0.2))\n",
            "    simple_GRU.add(keras.layers.BatchNormalization())\n",
            "    simple_GRU.add(keras.layers.GRU(256, return_sequences=False, activation=\"relu\"))\n",
            "    simple_GRU.add(keras.layers.Dropout(0.2))\n",
            "    simple_GRU.add(keras.layers.BatchNormalization())\n",
            "    # simple_GRU.add( keras.layers.Dense(64, activation='relu') )\n",
            "    # simple_GRU.add( keras.layers.Dropout(0.2) )\n",
            "    simple_GRU.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
            "    return simple_GRU\n",
            "\n",
            "\n",
            "# 3-stacked GRU model\n",
            "def stacked_GRU(input_sequence_shape):\n",
            "    stacked_GRU_model = keras.models.Sequential()\n",
            "    stacked_GRU_model.add(\n",
            "        keras.layers.Dense(\n",
            "            32, input_shape=(20, input_sequence_shape), activation=\"relu\"\n",
            "        )\n",
            "    )\n",
            "    stacked_GRU_model.add(keras.layers.Dropout(0.2))\n",
            "    stacked_GRU_model.add(keras.layers.BatchNormalization())\n",
            "    stacked_GRU_model.add(\n",
            "        keras.layers.GRU(256, return_sequences=True, activation=\"relu\")\n",
            "    )\n",
            "    stacked_GRU_model.add(\n",
            "        keras.layers.GRU(256, return_sequences=True, activation=\"relu\")\n",
            "    )\n",
            "    stacked_GRU_model.add(\n",
            "        keras.layers.GRU(256, return_sequences=False, activation=\"relu\")\n",
            "    )\n",
            "    stacked_GRU_model.add(keras.layers.Dropout(0.2))\n",
            "    stacked_GRU_model.add(keras.layers.BatchNormalization())\n",
            "    # stacked_GRU_model.add( keras.layers.Dense(64, activation='relu') )\n",
            "    # stacked_GRU_model.add( keras.layers.Dropout(0.2) )\n",
            "    stacked_GRU_model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
            "    return stacked_GRU_model\n",
            "\n",
            "\n",
            "# 3-stacked LSTM model\n",
            "def stacked_LSTM(input_sequence_shape):\n",
            "    stacked_LSTM_model = keras.models.Sequential()\n",
            "    stacked_LSTM_model.add(\n",
            "        keras.layers.Dense(\n",
            "            32, input_shape=(20, input_sequence_shape), activation=\"relu\"\n",
            "        )\n",
            "    )\n",
            "    stacked_LSTM_model.add(keras.layers.Dropout(0.2))\n",
            "    stacked_LSTM_model.add(keras.layers.BatchNormalization())\n",
            "    stacked_LSTM_model.add(\n",
            "        keras.layers.LSTM(256, return_sequences=True, activation=\"relu\")\n",
            "    )\n",
            "    stacked_LSTM_model.add(\n",
            "        keras.layers.LSTM(256, return_sequences=True, activation=\"relu\")\n",
            "    )\n",
            "    stacked_LSTM_model.add(\n",
            "        keras.layers.LSTM(256, return_sequences=False, activation=\"relu\")\n",
            "    )\n",
            "    stacked_LSTM_model.add(keras.layers.Dropout(0.2))\n",
            "    stacked_LSTM_model.add(keras.layers.BatchNormalization())\n",
            "    # stacked_LSTM_model.add( keras.layers.Dense(64, activation='relu') )\n",
            "    # stacked_LSTM_model.add( keras.layers.Dropout(0.2) )\n",
            "    stacked_LSTM_model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
            "    return stacked_LSTM_model\n",
            "\n",
            "\n",
            "# 3-stacked RNN model\n",
            "def stacked_RNN(input_sequence_shape):\n",
            "    stacked_RNN_model = keras.models.Sequential()\n",
            "    stacked_RNN_model.add(\n",
            "        keras.layers.Dense(\n",
            "            32, input_shape=(20, input_sequence_shape), activation=\"relu\"\n",
            "        )\n",
            "    )\n",
            "    stacked_RNN_model.add(keras.layers.Dropout(0.2))\n",
            "    stacked_RNN_model.add(keras.layers.BatchNormalization())\n",
            "    stacked_RNN_model.add(\n",
            "        keras.layers.SimpleRNN(256, return_sequences=True, activation=\"relu\")\n",
            "    )\n",
            "    stacked_RNN_model.add(\n",
            "        keras.layers.SimpleRNN(256, return_sequences=True, activation=\"relu\")\n",
            "    )\n",
            "    stacked_RNN_model.add(\n",
            "        keras.layers.SimpleRNN(256, return_sequences=False, activation=\"relu\")\n",
            "    )\n",
            "    stacked_RNN_model.add(keras.layers.Dropout(0.2))\n",
            "    stacked_RNN_model.add(keras.layers.BatchNormalization())\n",
            "    # stacked_RNN_model.add( keras.layers.Dense(64, activation='relu') )\n",
            "    # stacked_RNN_model.add( keras.layers.Dropout(0.2) )\n",
            "    stacked_RNN_model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
            "    return stacked_RNN_model"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Préparation des données"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [],
         "source": [
            "def import_dataset(\n",
            "    dataset_path,\n",
            "    columns=[\n",
            "        \"distance\",\n",
            "        \"distRealSR1\",\n",
            "        \"pos_y_rec_f\",\n",
            "        \"pos_y_rec\",\n",
            "        \"pos_x_rec_f\",\n",
            "        \"pos_x_rec\",\n",
            "        \"nb_packets_sent\",\n",
            "        \"label\",\n",
            "    ],\n",
            "    data_type={\n",
            "        \"label\":\"int8\"\n",
            "    }\n",
            "):\n",
            "    # Import du csv\n",
            "    data = pd.read_csv(\n",
            "        dataset_path,\n",
            "        usecols=columns,\n",
            "        index_col=False,\n",
            "        dtype=data_type\n",
            "    )\n",
            "\n",
            "    print(\"Nombre de lignes avant nettoyage : \", data.shape[0])\n",
            "\n",
            "    # On remplace les données infinies par nan si elles existent\n",
            "    data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
            "\n",
            "    # Drop les lignes avec nan\n",
            "    data.dropna(inplace=True)\n",
            "    print(\"Nombre de lignes après nettoyage : \", data.shape[0])\n",
            "\n",
            "    return data\n",
            "\n",
            "\n",
            "def sample_dataset(dataset, sample_nb):\n",
            "    return dataset.sample(sample_nb)\n",
            "\n",
            "def flat_sequence_creation(df):\n",
            "    senders_sequences = []\n",
            "    senders_label = []\n",
            "    senders = np.unique(df[\"sender\"].values)\n",
            "    for sender in senders:\n",
            "        # Données d'un seul sender rangée en fonction de l'heure d'envoi\n",
            "        sender_data_sorted = df.loc[df['sender'] == sender].sort_values(\"sendTime\")\n",
            "\n",
            "        # On récupère la valeur du label pour ce sender\n",
            "        \"\"\" On remplasse toute les valeur !=0 en 1 \"\"\"\n",
            "        if sender_data_sorted['label'].tolist()[0] != 0 :\n",
            "            label=1\n",
            "        else :\n",
            "            label = sender_data_sorted['label'].tolist()[0]\n",
            "        #On supprime les colonnes label et sender\n",
            "        sender_data_sorted = sender_data_sorted.drop([\"label\",\"sender\"], axis=1)\n",
            "        \n",
            "        #sequence_array = []\n",
            "\n",
            "        length = sender_data_sorted.shape[0]\n",
            "        slide = 10\n",
            "        start = 0\n",
            "        end = 20\n",
            "\n",
            "        # On vérifie qu'il est possible de faire une séquence de taille 20\n",
            "        while length > 20:\n",
            "            # Extraction par tranche de 20 avec une inter de 10\n",
            "            sequence = sender_data_sorted[start:end]\n",
            "\n",
            "            # Labels correspondant\n",
            "            #labels =  pd.Series.tolist(sequence[\"label\"])\n",
            "\n",
            "            # On transforme les 13 en 1, cette formule marche toujours si on met d'autres types d'attaques\n",
            "            #labels[:] = [x if x == 0 else 1 for x in labels]\n",
            "\n",
            "            # Attribution des tableaux numpy\n",
            "            senders_sequences.append(np.array(sequence.values.tolist(), dtype=np.float32))\n",
            "            senders_label.append(label)\n",
            "\n",
            "            # Mise à jour des variables\n",
            "            start += slide\n",
            "            end += slide\n",
            "            length -= 10\n",
            "        \n",
            "    print('Nombre de séquences : ',len(senders_sequences))\n",
            "    return senders_sequences, senders_label\n",
            "\n",
            "def data_preparation(df, sample=False, test_size=0.1):\n",
            "   \n",
            "    sorted_dataset = df.sort_values(\"sender\")\n",
            "    sequence_test, label_test = flat_sequence_creation(sorted_dataset)\n",
            "\n",
            "    # Transformation en array numpy\n",
            "    X = np.array(sequence_test)\n",
            "    y = np.array(label_test, dtype=np.float32)\n",
            "\n",
            "    # Réduire le temps de training en prenant les 100000 premiers éléments\n",
            "    if sample:\n",
            "        X = X[:100000]\n",
            "        y = y[:100000]\n",
            "    # Séparation en données d'entrainement et de test\n",
            "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
            "    print(\"X_train : \", X_train.shape)\n",
            "    print(\"y_train : \", y_train.shape)\n",
            "    print(\"X_test : \", X_test.shape)\n",
            "    print(\"y_test : \", y_test.shape)\n",
            "    \n",
            "    return X_train, X_test, y_train, y_test"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Import des données"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Chemin du dossier contenant tous les .csv\n",
            "data_folder = '../data'"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "metadata": {},
         "outputs": [],
         "source": [
            "# selected_columns = [\n",
            "# \"nb_packets_sent\",\n",
            "# \"distance\",\n",
            "# \"distRealSR1\",\n",
            "# \"pos_y_rec_f\",\n",
            "# \"pos_y_rec\",\n",
            "# \"pos_x_rec_f\",\n",
            "# \"pos_x_rec\",\n",
            "# \"pos_x_send\",\n",
            "# \"pos_y_send\",\n",
            "# \"spd_x_send\",\n",
            "# \"spd_y_send\",\n",
            "# \"sendTime\",\n",
            "# \"receiver\",\n",
            "# \"sender\",\n",
            "# \"label\"\n",
            "# ]\n",
            "selected_columns = [\n",
            "\"distance\",\n",
            "\"pos_x_send\",\n",
            "\"pos_y_send\",\n",
            "\"spd_x_send\",\n",
            "\"spd_y_send\",\n",
            "\"sendTime\",\n",
            "\"sender\",\n",
            "\"label\"\n",
            "]\n",
            "\n",
            "input_sequence_shape = len(selected_columns)-2 # On drop label et sender dans la création de séquences\n",
            "\n",
            "data_type = {\n",
            "    \"label\":\"int8\",\n",
            "    \"sender\":\"int16\",\n",
            "    \"receiver\":\"int16\",\n",
            "    \"nb_packets_sent\":\"int16\"\n",
            "    \n",
            "}"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Import de la base de données"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Colonnes choisies - label, sender & sendTime obligatoires\n",
            "# selected_columns = [\n",
            "# \"nb_packets_sent\",\n",
            "# \"distance\",\n",
            "# \"distRealSR1\",\n",
            "# \"pos_y_rec_f\",\n",
            "# \"pos_y_rec\",\n",
            "# \"pos_x_rec_f\",\n",
            "# \"pos_x_rec\",\n",
            "# \"pos_x_send\",\n",
            "# \"pos_y_send\",\n",
            "# \"spd_x_send\",\n",
            "# \"spd_y_send\",\n",
            "# \"sendTime\",\n",
            "# \"receiver\",\n",
            "# \"sender\",\n",
            "# \"label\"\n",
            "# ]\n",
            "selected_columns = [\n",
            "\"distance\",\n",
            "\"pos_x_send\",\n",
            "\"pos_y_send\",\n",
            "\"spd_x_send\",\n",
            "\"spd_y_send\",\n",
            "\"sendTime\",\n",
            "\"sender\",\n",
            "\"label\"\n",
            "]\n",
            "\n",
            "input_sequence_shape = len(selected_columns)-2 # On drop label et sender dans la création de séquences\n",
            "\n",
            "data_type = {\n",
            "    \"label\":\"int8\",\n",
            "    \"sender\":\"int16\",\n",
            "    \"receiver\":\"int16\",\n",
            "    \"nb_packets_sent\":\"int16\"\n",
            "    \n",
            "}"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Nombre de lignes avant nettoyage :  4753433\n",
                  "Nombre de lignes après nettoyage :  4753433\n"
               ]
            }
         ],
         "source": [
            "# DoS (13)\n",
            "df_13 = import_dataset(data_folder + '/DoS_0709_new_columns.csv', selected_columns, data_type)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Nombre de lignes avant nettoyage :  4679311\n",
                  "Nombre de lignes après nettoyage :  4679311\n"
               ]
            }
         ],
         "source": [
            "# DoS Random (14)\n",
            "df_14 = import_dataset(data_folder + '/DoS_Random_0709_new_columns.csv', selected_columns, data_type)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# DoS Disruptive (15)\n",
            "df_15 = import_dataset(data_folder + '/DoS_Disruptive_0709_new_columns.csv', selected_columns)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# DoS Random Sybil (18)\n",
            "df_18 = import_dataset(data_folder + '/DoS_Random_Sybil_0709_new_columns.csv', selected_columns)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# DoS Disruptive Sybil (19)\n",
            "df_19 = import_dataset(data_folder + '/DoS_Disruptive_Sybil_0709_new_columns.csv', selected_columns)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 15,
         "metadata": {},
         "outputs": [],
         "source": [
            "# attack_types = [13, 14, 15, 18, 19]\n",
            "attack_types = [13, 14]\n",
            "# dataframes = [df_13, df_14, df_15, df_18, df_19]\n",
            "dataframes = [df_13, df_14]"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Entrainement des modèles pour chaque dataset"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "metadata": {},
         "outputs": [],
         "source": [
            "EPOCHS = 20\n",
            "VAL_SPLIT = 0.3\n",
            "ADAM = keras.optimizers.Adam(learning_rate=0.0003)\n",
            "callback = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 18,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Nombre de séquences :  469053\n",
                  "X_train :  (900, 20, 6)\n",
                  "y_train :  (900,)\n",
                  "X_test :  (100, 20, 6)\n",
                  "y_test :  (100,)\n",
                  "Training 2 stacked RNN model\n",
                  "Epoch 1/20\n",
                  "5/5 [==============================] - 5s 404ms/step - loss: 0.8534 - accuracy: 0.5063 - val_loss: 0.7680 - val_accuracy: 0.6407\n",
                  "Epoch 2/20\n",
                  "5/5 [==============================] - 1s 114ms/step - loss: 0.7846 - accuracy: 0.5333 - val_loss: 2.3460 - val_accuracy: 0.6407\n",
                  "Epoch 3/20\n",
                  "5/5 [==============================] - 1s 133ms/step - loss: 0.7478 - accuracy: 0.5492 - val_loss: 3.4629 - val_accuracy: 0.6407\n",
                  "Epoch 4/20\n",
                  "5/5 [==============================] - 1s 123ms/step - loss: 0.7312 - accuracy: 0.5571 - val_loss: 0.9184 - val_accuracy: 0.6407\n",
                  "Epoch 5/20\n",
                  "5/5 [==============================] - 1s 134ms/step - loss: 0.7252 - accuracy: 0.5492 - val_loss: 0.8210 - val_accuracy: 0.3593\n",
                  "Epoch 6/20\n",
                  "5/5 [==============================] - 1s 158ms/step - loss: 0.6906 - accuracy: 0.5730 - val_loss: 0.8948 - val_accuracy: 0.6407\n",
                  "4/4 [==============================] - 0s 13ms/step - loss: 0.8697 - accuracy: 0.6000\n",
                  "Training stacked small LSTM model\n",
                  "Epoch 1/20\n",
                  "20/20 [==============================] - 7s 118ms/step - loss: 0.6722 - accuracy: 0.6508 - val_loss: 0.6604 - val_accuracy: 0.6407\n",
                  "Epoch 2/20\n",
                  "20/20 [==============================] - 1s 52ms/step - loss: 0.6494 - accuracy: 0.6587 - val_loss: 0.6539 - val_accuracy: 0.6407\n",
                  "Epoch 3/20\n",
                  "20/20 [==============================] - 1s 48ms/step - loss: 0.6439 - accuracy: 0.6587 - val_loss: 0.6530 - val_accuracy: 0.6407\n",
                  "Epoch 4/20\n",
                  "20/20 [==============================] - 1s 70ms/step - loss: 0.6426 - accuracy: 0.6587 - val_loss: 0.6533 - val_accuracy: 0.6407\n",
                  "Epoch 5/20\n",
                  "20/20 [==============================] - 1s 50ms/step - loss: 0.6424 - accuracy: 0.6587 - val_loss: 0.6536 - val_accuracy: 0.6407\n",
                  "Epoch 6/20\n",
                  "20/20 [==============================] - 1s 44ms/step - loss: 0.6424 - accuracy: 0.6587 - val_loss: 0.6536 - val_accuracy: 0.6407\n",
                  "4/4 [==============================] - 0s 13ms/step - loss: 0.6738 - accuracy: 0.6000\n",
                  "Training RNN-LSTM model\n",
                  "Epoch 1/20\n",
                  "20/20 [==============================] - 5s 71ms/step - loss: nan - accuracy: 0.3460 - val_loss: nan - val_accuracy: 0.3593\n",
                  "Epoch 2/20\n",
                  "20/20 [==============================] - 1s 28ms/step - loss: nan - accuracy: 0.3413 - val_loss: nan - val_accuracy: 0.3593\n",
                  "Epoch 3/20\n",
                  "20/20 [==============================] - 1s 28ms/step - loss: nan - accuracy: 0.3413 - val_loss: nan - val_accuracy: 0.3593\n",
                  "Epoch 4/20\n",
                  "20/20 [==============================] - 1s 28ms/step - loss: nan - accuracy: 0.3413 - val_loss: nan - val_accuracy: 0.3593\n",
                  "Epoch 5/20\n",
                  "20/20 [==============================] - 1s 28ms/step - loss: nan - accuracy: 0.3413 - val_loss: nan - val_accuracy: 0.3593\n",
                  "Epoch 6/20\n",
                  "20/20 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.3413 - val_loss: nan - val_accuracy: 0.3593\n",
                  "4/4 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.4000\n",
                  "Training 3 stacked GRU\n",
                  "Epoch 1/20\n",
                  "10/10 [==============================] - 10s 359ms/step - loss: 0.7320 - accuracy: 0.4968 - val_loss: 0.6651 - val_accuracy: 0.6407\n",
                  "Epoch 2/20\n",
                  "10/10 [==============================] - 3s 326ms/step - loss: 0.7218 - accuracy: 0.5222 - val_loss: 0.6741 - val_accuracy: 0.6407\n",
                  "Epoch 3/20\n",
                  "10/10 [==============================] - 4s 360ms/step - loss: 0.6884 - accuracy: 0.5444 - val_loss: 0.6683 - val_accuracy: 0.6407\n",
                  "Epoch 4/20\n",
                  "10/10 [==============================] - 4s 391ms/step - loss: 0.6838 - accuracy: 0.5444 - val_loss: 0.6681 - val_accuracy: 0.6407\n",
                  "Epoch 5/20\n",
                  "10/10 [==============================] - 4s 422ms/step - loss: 0.6799 - accuracy: 0.5794 - val_loss: 0.6689 - val_accuracy: 0.6407\n",
                  "Epoch 6/20\n",
                  "10/10 [==============================] - 3s 306ms/step - loss: 0.6748 - accuracy: 0.5635 - val_loss: 0.6652 - val_accuracy: 0.6407\n",
                  "4/4 [==============================] - 0s 73ms/step - loss: 0.6762 - accuracy: 0.6000\n",
                  "Training simple GRU\n",
                  "Epoch 1/20\n",
                  "10/10 [==============================] - 5s 172ms/step - loss: 0.8154 - accuracy: 0.5063 - val_loss: 0.6598 - val_accuracy: 0.6407\n",
                  "Epoch 2/20\n",
                  "10/10 [==============================] - 1s 107ms/step - loss: 0.8079 - accuracy: 0.4968 - val_loss: 0.6531 - val_accuracy: 0.6407\n",
                  "Epoch 3/20\n",
                  "10/10 [==============================] - 1s 100ms/step - loss: 0.7373 - accuracy: 0.5429 - val_loss: 0.6528 - val_accuracy: 0.6407\n",
                  "Epoch 4/20\n",
                  "10/10 [==============================] - 1s 101ms/step - loss: 0.7930 - accuracy: 0.5063 - val_loss: 0.6517 - val_accuracy: 0.6407\n",
                  "Epoch 5/20\n",
                  "10/10 [==============================] - 1s 107ms/step - loss: 0.7954 - accuracy: 0.5238 - val_loss: 0.6531 - val_accuracy: 0.6407\n",
                  "Epoch 6/20\n",
                  "10/10 [==============================] - 1s 113ms/step - loss: 0.7515 - accuracy: 0.5540 - val_loss: 0.6527 - val_accuracy: 0.6407\n",
                  "4/4 [==============================] - 0s 14ms/step - loss: 0.6930 - accuracy: 0.6000\n",
                  "Training 3 stacked LSTM\n",
                  "Epoch 1/20\n",
                  "10/10 [==============================] - 12s 584ms/step - loss: 0.4902 - accuracy: 0.5429 - val_loss: 0.5615 - val_accuracy: 0.3593\n",
                  "Epoch 2/20\n",
                  "10/10 [==============================] - 4s 399ms/step - loss: 0.4752 - accuracy: 0.5429 - val_loss: 0.5476 - val_accuracy: 0.3593\n",
                  "Epoch 3/20\n",
                  "10/10 [==============================] - 4s 387ms/step - loss: 0.4658 - accuracy: 0.5683 - val_loss: 0.5377 - val_accuracy: 0.3926\n",
                  "Epoch 4/20\n",
                  "10/10 [==============================] - 4s 388ms/step - loss: 0.4541 - accuracy: 0.5635 - val_loss: 0.4812 - val_accuracy: 0.5704\n",
                  "Epoch 5/20\n",
                  "10/10 [==============================] - 4s 431ms/step - loss: 0.4407 - accuracy: 0.5873 - val_loss: 0.6233 - val_accuracy: 0.3593\n",
                  "Epoch 6/20\n",
                  "10/10 [==============================] - 4s 363ms/step - loss: 0.4025 - accuracy: 0.6190 - val_loss: 0.5803 - val_accuracy: 0.4037\n",
                  "Epoch 7/20\n",
                  "10/10 [==============================] - 4s 384ms/step - loss: 0.3788 - accuracy: 0.6270 - val_loss: 0.5418 - val_accuracy: 0.4778\n",
                  "Epoch 8/20\n",
                  "10/10 [==============================] - 4s 408ms/step - loss: 0.3828 - accuracy: 0.6349 - val_loss: 0.5045 - val_accuracy: 0.4963\n",
                  "Epoch 9/20\n",
                  "10/10 [==============================] - 5s 462ms/step - loss: 0.3785 - accuracy: 0.6270 - val_loss: 0.5112 - val_accuracy: 0.4852\n",
                  "4/4 [==============================] - 0s 58ms/step - loss: 0.4546 - accuracy: 0.5700\n",
                  "Nombre de séquences :  461621\n",
                  "X_train :  (900, 20, 6)\n",
                  "y_train :  (900,)\n",
                  "X_test :  (100, 20, 6)\n",
                  "y_test :  (100,)\n",
                  "Training 2 stacked RNN model\n",
                  "Epoch 1/20\n",
                  "5/5 [==============================] - 8s 359ms/step - loss: 0.5869 - accuracy: 0.7063 - val_loss: 0.2015 - val_accuracy: 0.9185\n",
                  "Epoch 2/20\n",
                  "5/5 [==============================] - 1s 158ms/step - loss: 0.2411 - accuracy: 0.9032 - val_loss: 0.2203 - val_accuracy: 0.9741\n",
                  "Epoch 3/20\n",
                  "5/5 [==============================] - 1s 168ms/step - loss: 0.1160 - accuracy: 0.9651 - val_loss: 0.1864 - val_accuracy: 0.9926\n",
                  "Epoch 4/20\n",
                  "5/5 [==============================] - 1s 148ms/step - loss: 0.1400 - accuracy: 0.9556 - val_loss: 3.8812 - val_accuracy: 0.7778\n",
                  "Epoch 5/20\n",
                  "5/5 [==============================] - 1s 147ms/step - loss: 0.0633 - accuracy: 0.9825 - val_loss: 1.3103 - val_accuracy: 0.8963\n",
                  "Epoch 6/20\n",
                  "5/5 [==============================] - 1s 183ms/step - loss: 0.0507 - accuracy: 0.9857 - val_loss: 1.0971 - val_accuracy: 0.8704\n",
                  "Epoch 7/20\n",
                  "5/5 [==============================] - 1s 155ms/step - loss: 0.0569 - accuracy: 0.9873 - val_loss: 0.2161 - val_accuracy: 0.9593\n",
                  "Epoch 8/20\n",
                  "5/5 [==============================] - 1s 169ms/step - loss: 0.0389 - accuracy: 0.9937 - val_loss: 0.2438 - val_accuracy: 0.9704\n",
                  "4/4 [==============================] - 0s 16ms/step - loss: 5.5563e-07 - accuracy: 1.0000\n",
                  "Training stacked small LSTM model\n",
                  "Epoch 1/20\n",
                  "20/20 [==============================] - 7s 119ms/step - loss: 0.6758 - accuracy: 0.6016 - val_loss: 0.6577 - val_accuracy: 0.6370\n",
                  "Epoch 2/20\n",
                  "20/20 [==============================] - 1s 72ms/step - loss: 0.6727 - accuracy: 0.6048 - val_loss: 0.6557 - val_accuracy: 0.6370\n",
                  "Epoch 3/20\n",
                  "20/20 [==============================] - 2s 89ms/step - loss: 0.6720 - accuracy: 0.6048 - val_loss: 0.6567 - val_accuracy: 0.6370\n",
                  "Epoch 4/20\n",
                  "20/20 [==============================] - 1s 71ms/step - loss: 0.6716 - accuracy: 0.6048 - val_loss: 0.6552 - val_accuracy: 0.6370\n",
                  "Epoch 5/20\n",
                  "20/20 [==============================] - 2s 77ms/step - loss: 0.6720 - accuracy: 0.6048 - val_loss: 0.6554 - val_accuracy: 0.6370\n",
                  "Epoch 6/20\n",
                  "20/20 [==============================] - 1s 72ms/step - loss: 0.6719 - accuracy: 0.6048 - val_loss: 0.6552 - val_accuracy: 0.6370\n",
                  "4/4 [==============================] - 0s 18ms/step - loss: 0.6606 - accuracy: 0.6300\n",
                  "Training RNN-LSTM model\n",
                  "Epoch 1/20\n",
                  "20/20 [==============================] - 5s 94ms/step - loss: 0.6946 - accuracy: 0.5286 - val_loss: 269.2132 - val_accuracy: 0.6370\n",
                  "Epoch 2/20\n",
                  "20/20 [==============================] - 2s 86ms/step - loss: 0.6757 - accuracy: 0.6111 - val_loss: 1.1523 - val_accuracy: 0.6370\n",
                  "Epoch 3/20\n",
                  "20/20 [==============================] - 1s 72ms/step - loss: 0.6819 - accuracy: 0.6048 - val_loss: 0.6817 - val_accuracy: 0.6370\n",
                  "Epoch 4/20\n",
                  "20/20 [==============================] - 1s 60ms/step - loss: 0.6768 - accuracy: 0.6048 - val_loss: 2.0097 - val_accuracy: 0.6370\n",
                  "Epoch 5/20\n",
                  "20/20 [==============================] - 1s 53ms/step - loss: 0.6686 - accuracy: 0.6048 - val_loss: 0.6876 - val_accuracy: 0.6370\n",
                  "Epoch 6/20\n",
                  "20/20 [==============================] - 1s 58ms/step - loss: 0.6514 - accuracy: 0.6048 - val_loss: 0.7342 - val_accuracy: 0.3630\n",
                  "4/4 [==============================] - 0s 15ms/step - loss: 280.2827 - accuracy: 0.6300\n",
                  "Training 3 stacked GRU\n",
                  "Epoch 1/20\n",
                  "10/10 [==============================] - 11s 498ms/step - loss: 0.5795 - accuracy: 0.6889 - val_loss: 0.9473 - val_accuracy: 0.3630\n",
                  "Epoch 2/20\n",
                  "10/10 [==============================] - 4s 435ms/step - loss: 0.4733 - accuracy: 0.7762 - val_loss: 0.6739 - val_accuracy: 0.7519\n",
                  "Epoch 3/20\n",
                  "10/10 [==============================] - 4s 364ms/step - loss: 0.5152 - accuracy: 0.7429 - val_loss: 0.6445 - val_accuracy: 0.6370\n",
                  "Epoch 4/20\n",
                  "10/10 [==============================] - 3s 340ms/step - loss: 0.6330 - accuracy: 0.6365 - val_loss: 0.6472 - val_accuracy: 0.6370\n",
                  "Epoch 5/20\n",
                  "10/10 [==============================] - 4s 414ms/step - loss: 0.5862 - accuracy: 0.6825 - val_loss: 0.6448 - val_accuracy: 0.6370\n",
                  "Epoch 6/20\n",
                  "10/10 [==============================] - 4s 403ms/step - loss: 0.5224 - accuracy: 0.7540 - val_loss: 0.6765 - val_accuracy: 0.6519\n",
                  "Epoch 7/20\n",
                  "10/10 [==============================] - 4s 380ms/step - loss: 0.4876 - accuracy: 0.7794 - val_loss: 0.6499 - val_accuracy: 0.6370\n",
                  "4/4 [==============================] - 0s 100ms/step - loss: 0.6710 - accuracy: 0.8000\n",
                  "Training simple GRU\n",
                  "Epoch 1/20\n",
                  "10/10 [==============================] - 4s 192ms/step - loss: 0.7365 - accuracy: 0.5952 - val_loss: 0.8037 - val_accuracy: 0.6370\n",
                  "Epoch 2/20\n",
                  "10/10 [==============================] - 1s 142ms/step - loss: 0.6800 - accuracy: 0.6175 - val_loss: 0.6644 - val_accuracy: 0.6370\n",
                  "Epoch 3/20\n",
                  "10/10 [==============================] - 1s 143ms/step - loss: 0.6618 - accuracy: 0.6492 - val_loss: 0.6459 - val_accuracy: 0.6370\n",
                  "Epoch 4/20\n",
                  "10/10 [==============================] - 1s 113ms/step - loss: 0.6803 - accuracy: 0.6175 - val_loss: 0.8378 - val_accuracy: 0.6370\n",
                  "Epoch 5/20\n",
                  "10/10 [==============================] - 2s 153ms/step - loss: 0.7108 - accuracy: 0.6095 - val_loss: 0.6682 - val_accuracy: 0.6370\n",
                  "Epoch 6/20\n",
                  "10/10 [==============================] - 1s 140ms/step - loss: 0.6809 - accuracy: 0.6206 - val_loss: 0.6791 - val_accuracy: 0.6370\n",
                  "4/4 [==============================] - 0s 17ms/step - loss: 0.8118 - accuracy: 0.6300\n",
                  "Training 3 stacked LSTM\n",
                  "Epoch 1/20\n",
                  "10/10 [==============================] - 11s 593ms/step - loss: 0.2794 - accuracy: 0.8127 - val_loss: 0.2879 - val_accuracy: 0.7111\n",
                  "Epoch 2/20\n",
                  "10/10 [==============================] - 5s 499ms/step - loss: 0.1362 - accuracy: 0.8746 - val_loss: 0.3284 - val_accuracy: 0.6704\n",
                  "Epoch 3/20\n",
                  "10/10 [==============================] - 5s 452ms/step - loss: 0.1230 - accuracy: 0.8905 - val_loss: 0.1192 - val_accuracy: 0.8815\n",
                  "Epoch 4/20\n",
                  "10/10 [==============================] - 4s 425ms/step - loss: 0.1078 - accuracy: 0.8984 - val_loss: 0.1208 - val_accuracy: 0.8963\n",
                  "Epoch 5/20\n",
                  "10/10 [==============================] - 4s 407ms/step - loss: 0.1129 - accuracy: 0.8952 - val_loss: 0.1298 - val_accuracy: 0.9037\n",
                  "Epoch 6/20\n",
                  "10/10 [==============================] - 6s 671ms/step - loss: 0.1131 - accuracy: 0.8873 - val_loss: 0.1319 - val_accuracy: 0.9259\n",
                  "Epoch 7/20\n",
                  "10/10 [==============================] - 5s 517ms/step - loss: 0.1041 - accuracy: 0.9048 - val_loss: 0.1470 - val_accuracy: 0.9481\n",
                  "Epoch 8/20\n",
                  "10/10 [==============================] - 5s 565ms/step - loss: 0.0889 - accuracy: 0.9159 - val_loss: 0.1646 - val_accuracy: 0.9444\n",
                  "Epoch 9/20\n",
                  "10/10 [==============================] - 5s 522ms/step - loss: 0.0941 - accuracy: 0.9095 - val_loss: 0.2089 - val_accuracy: 0.8704\n",
                  "Epoch 10/20\n",
                  "10/10 [==============================] - 7s 669ms/step - loss: 0.0894 - accuracy: 0.9175 - val_loss: 0.1942 - val_accuracy: 0.9222\n",
                  "Epoch 11/20\n",
                  "10/10 [==============================] - 6s 636ms/step - loss: 0.0719 - accuracy: 0.9302 - val_loss: 0.2191 - val_accuracy: 0.9185\n",
                  "Epoch 12/20\n",
                  "10/10 [==============================] - 4s 431ms/step - loss: 0.0602 - accuracy: 0.9413 - val_loss: 0.2364 - val_accuracy: 0.9519\n",
                  "Epoch 13/20\n",
                  "10/10 [==============================] - 4s 426ms/step - loss: 0.0584 - accuracy: 0.9508 - val_loss: 0.2323 - val_accuracy: 0.9630\n",
                  "Epoch 14/20\n",
                  "10/10 [==============================] - 4s 417ms/step - loss: 0.0472 - accuracy: 0.9556 - val_loss: 0.2196 - val_accuracy: 0.9630\n",
                  "Epoch 15/20\n",
                  "10/10 [==============================] - 4s 402ms/step - loss: 0.0541 - accuracy: 0.9444 - val_loss: 0.2351 - val_accuracy: 0.9630\n",
                  "Epoch 16/20\n",
                  "10/10 [==============================] - 4s 429ms/step - loss: 0.0677 - accuracy: 0.9349 - val_loss: 0.2363 - val_accuracy: 0.9741\n",
                  "Epoch 17/20\n",
                  "10/10 [==============================] - 4s 439ms/step - loss: 0.0532 - accuracy: 0.9492 - val_loss: 0.2377 - val_accuracy: 0.9593\n",
                  "Epoch 18/20\n",
                  "10/10 [==============================] - 5s 517ms/step - loss: 0.0345 - accuracy: 0.9762 - val_loss: 0.2512 - val_accuracy: 0.9593\n",
                  "Epoch 19/20\n",
                  "10/10 [==============================] - 4s 409ms/step - loss: 0.0320 - accuracy: 0.9730 - val_loss: 0.2403 - val_accuracy: 0.9556\n",
                  "Epoch 20/20\n",
                  "10/10 [==============================] - 4s 435ms/step - loss: 0.0275 - accuracy: 0.9746 - val_loss: 0.2463 - val_accuracy: 0.9519\n",
                  "4/4 [==============================] - 0s 87ms/step - loss: 0.2377 - accuracy: 0.9500\n"
               ]
            }
         ],
         "source": [
            "evaluation_dataframe = pd.DataFrame()\n",
            "for i in range(len(dataframes)):\n",
            "    X_train, X_test, y_train, y_test = data_preparation(dataframes[i], sample=False)\n",
            "\n",
            "    # 2-stacked RNN\n",
            "    print(\"\\nTraining 2 stacked RNN model\\n\")\n",
            "    rnn_model = stacked_RNN(input_sequence_shape=input_sequence_shape)\n",
            "    rnn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics='accuracy')\n",
            "    history = rnn_model.fit(X_train, y_train, epochs=EPOCHS, batch_size=128, validation_split=VAL_SPLIT, callbacks=[callback])\n",
            "    eval=rnn_model.evaluate(X_test, y_test)\n",
            "    evaluation_dataframe = pd.concat([evaluation_dataframe, pd.DataFrame({'dataset':[attack_types[i]], 'modele':['2-stacked-rnn'], 'accuracy':[eval[1]]})])\n",
            "\n",
            "    # stacked LSTM small\n",
            "    print(\"\\nTraining stacked small LSTM model\\n\")\n",
            "    lstm_model = stacked_LSTM_small(input_sequence_shape)\n",
            "    opt = keras.optimizers.SGD(learning_rate=0.01)\n",
            "    lstm_model.compile(loss='binary_crossentropy', optimizer=opt, metrics='accuracy')\n",
            "    history = lstm_model.fit(X_train, y_train, epochs=EPOCHS, batch_size=32, validation_split=VAL_SPLIT, callbacks=[callback])\n",
            "    eval=lstm_model.evaluate(X_test, y_test)\n",
            "    evaluation_dataframe = pd.concat([evaluation_dataframe, pd.DataFrame({'dataset':[attack_types[i]], 'modele':['stacked-small-lstm'], 'accuracy':[eval[1]]})])\n",
            "\n",
            "    # mix lstm rnn\n",
            "    print(\"\\nTraining RNN-LSTM model\\n\")\n",
            "    lstm_rnn_model = mix_rnn_lstm(input_sequence_shape)\n",
            "    opt = keras.optimizers.SGD(learning_rate=0.01)\n",
            "    lstm_rnn_model.compile(loss='binary_crossentropy', optimizer=opt, metrics='accuracy')\n",
            "    history = lstm_rnn_model.fit(X_train, y_train, epochs=EPOCHS, batch_size=32, validation_split=VAL_SPLIT, callbacks=[callback])\n",
            "    eval=lstm_rnn_model.evaluate(X_test, y_test)\n",
            "    evaluation_dataframe = pd.concat([evaluation_dataframe, pd.DataFrame({'dataset':[attack_types[i]], 'modele':['lstm-rnn'], 'accuracy':[eval[1]]})])\n",
            "\n",
            "    # 3 Stacked GRU\n",
            "    print(\"\\nTraining 3 stacked GRU\\n\")\n",
            "    stacked_GRU_model = stacked_GRU(input_sequence_shape)\n",
            "    opt = keras.optimizers.SGD(learning_rate=0.01)\n",
            "    stacked_GRU_model.compile(loss='binary_crossentropy', optimizer=opt, metrics='accuracy')\n",
            "    history = stacked_GRU_model.fit(X_train, y_train, epochs=EPOCHS, batch_size=64, validation_split=VAL_SPLIT, callbacks=[callback])\n",
            "    eval=stacked_GRU_model.evaluate(X_test, y_test)\n",
            "    evaluation_dataframe = pd.concat([evaluation_dataframe, pd.DataFrame({'dataset':[attack_types[i]], 'modele':['3-stacked-GRU'], 'accuracy':[eval[1]]})])\n",
            "\n",
            "    # simple GRU\n",
            "    print(\"\\nTraining simple GRU\\n\")\n",
            "    simple_GRU_model = simple_GRU(input_sequence_shape)\n",
            "    opt = keras.optimizers.SGD(learning_rate=0.01)\n",
            "    simple_GRU_model.compile(loss='binary_crossentropy', optimizer=opt, metrics='accuracy')\n",
            "    history = simple_GRU_model.fit(X_train, y_train, epochs=EPOCHS, batch_size=64, validation_split=VAL_SPLIT, callbacks=[callback])\n",
            "    eval=simple_GRU_model.evaluate(X_test, y_test)\n",
            "    evaluation_dataframe = pd.concat([evaluation_dataframe, pd.DataFrame({'dataset':[attack_types[i]], 'modele':['simple-gru'], 'accuracy':[eval[1]]})])\n",
            "\n",
            "    # stacked LSTM\n",
            "    print(\"\\nTraining 3 stacked LSTM\\n\")\n",
            "    stacked_LSTM_model = stacked_LSTM(input_sequence_shape)\n",
            "    stacked_LSTM_model.compile(loss='mean_absolute_error', optimizer=ADAM, metrics='accuracy')\n",
            "    history = stacked_LSTM_model.fit(X_train, y_train, epochs=EPOCHS, batch_size=64, validation_split=VAL_SPLIT, callbacks=[callback])\n",
            "    eval = stacked_LSTM_model.evaluate(X_test, y_test)\n",
            "    evaluation_dataframe = pd.concat([evaluation_dataframe, pd.DataFrame({'dataset':[attack_types[i]], 'modele':['3-stacked-LSTM'], 'accuracy':[eval[1]]})])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 21,
         "metadata": {},
         "outputs": [],
         "source": [
            "evaluation_dataframe.to_csv('results_accuracy.csv')"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "cy",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.8.3"
      },
      "orig_nbformat": 4,
      "vscode": {
         "interpreter": {
            "hash": "62676a739a12458da1789023e3b8ff577b389322e46d1a1cbf9699674fd76d84"
         }
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
